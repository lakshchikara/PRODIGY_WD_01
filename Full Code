!pip install transformers datasets
!pip install --upgrade accelerate

from transformers import GPT2Tokenizer

tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
tokenizer.pad_token = tokenizer.eos_token  

with open("custom_dataset.txt", "r", encoding='utf-8') as f:
    data = f.read()

tokens = tokenizer(data, return_tensors='pt', truncation=True, padding=True)

from transformers import GPT2LMHeadModel

model = GPT2LMHeadModel.from_pretrained("gpt2")
model.resize_token_embeddings(len(tokenizer))  

from transformers import Trainer, TrainingArguments

from datasets import Dataset

# Convert to list of input sequences
input_ids = tokens["input_ids"]

# Make 'labels' the same as 'input_ids'
dataset = Dataset.from_dict({
    "input_ids": input_ids,
    "labels": input_ids
})


training_args = TrainingArguments(
    output_dir="./gpt2-finetuned",
    overwrite_output_dir=True,
    num_train_epochs=3,
    per_device_train_batch_size=1,
    save_steps=500,
    save_total_limit=2,
    logging_steps=100
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset
)

trainer.train()

from transformers import pipeline

generator = pipeline('text-generation', model=model, tokenizer=tokenizer)

prompt = "The future of AI is"
result = generator(prompt, max_length=100, num_return_sequences=1)

print(result[0]['generated_text'])

